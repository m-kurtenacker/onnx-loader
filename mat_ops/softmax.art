#[intern]
fn @matrix_softmax (manager: PassManager, mat: Tensor1[f32], output_size: &[i64]) -> Tensor1[f32] {
    let output_size_fixed = [output_size(0)];
    let output = @alloc_tensor_layout_1[f32](manager, output_size_fixed, AllocLayout::RCK);

    let mut sum = 0 as f32;
    //let sump = &mut sum;

    for instance in multi_loop (manager, 1, output_size) {
        let index = [instance.index(0)];

        let data = math_builtins::exp(*mat.access_fn(index));
        *output.access_fn(index) = data;
        sum += data;
        //atomic[f32](11, sump, data, 7, "");
    }

    for instance in multi_loop (manager, 1, output_size) {
        let index = [instance.index(0)];

        let data = *output.access_fn(index);
        *output.access_fn(index) = data / sum;
    }

    output
}

#[intern]
fn @matrix_log_softmax (manager: PassManager, mat: Tensor1[f32], output_size: &[i64]) -> Tensor1[f32] {
    let output_size_fixed = [output_size(0)];
    let output = @alloc_tensor_layout_1[f32](manager, output_size_fixed, AllocLayout::RCK);

    let mut sum = 0 as f32;
    //let sump = &mut sum;

    for instance in multi_loop (manager, 1, output_size) {
        let index = [instance.index(0)];

        let data = math_builtins::exp(*mat.access_fn(index));
        *output.access_fn(index) = data;
        sum += data;
        //atomic[f32](11, sump, data, 7, "");
    }

    for instance in multi_loop (manager, 1, output_size) {
        let index = [instance.index(0)];

        let data = *output.access_fn(index);
        *output.access_fn(index) = math_builtins::log(data / sum);
    }

    output
}

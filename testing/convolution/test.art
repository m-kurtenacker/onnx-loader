#[export]
fn main() -> () {
    let data = read_idx_scaled("test.idx");

    let tensor_input_buffer = data(0);

    let mut result_buffer : Buffer;

    let tensor_input = build_tensor_f32(tensor_input_buffer, 4, @|n : i32| { match n { 0 => 1, 1 => 1, 2 => 4, 3 => 3, _ => 0 }});
    print_tensor_256("input", tensor_input);

    let tensor_weight = alloc_tensor_f32(4, @|n: i32| { match n { 0 => 2, 1 => 1, 2 => 2, 3 => 2, _ => 0 }});
    *tensor_weight.access_fn([0: i64, 0: i64, 0: i64, 0: i64]) = -1 : f32;
    *tensor_weight.access_fn([0: i64, 0: i64, 0: i64, 1: i64]) =  1 : f32;
    *tensor_weight.access_fn([0: i64, 0: i64, 1: i64, 0: i64]) = -1 : f32;
    *tensor_weight.access_fn([0: i64, 0: i64, 1: i64, 1: i64]) =  1 : f32;

    *tensor_weight.access_fn([1: i64, 0: i64, 0: i64, 0: i64]) = -1 : f32;
    *tensor_weight.access_fn([1: i64, 0: i64, 0: i64, 1: i64]) = -1 : f32;
    *tensor_weight.access_fn([1: i64, 0: i64, 1: i64, 0: i64]) =  1 : f32;
    *tensor_weight.access_fn([1: i64, 0: i64, 1: i64, 1: i64]) =  1 : f32;
    print_tensor("weight", tensor_weight);

    let tensor_bias = alloc_tensor_f32(1, @|n: i32| { match n { 0 => 2, _ => 0 }});
    *tensor_bias.access_fn([0: i64]) = 0 : f32;
    *tensor_bias.access_fn([1: i64]) = 0 : f32;
    print_tensor("bias", tensor_bias);

    let output_size = (4, [1: i64, 2: i64, 3: i64, 2: i64]);
    let kernel_shape = (2, [2: i64, 2: i64]);
    let stride = (2, [1: i64; 2]);
    let padding = (4, [0: i64; 4]);

    let result_tensor = @matrix_convolution_padded(tensor_input, tensor_weight, tensor_bias, output_size, kernel_shape, stride, padding);

    print_tensor_256("result", result_tensor);

    result_buffer = result_tensor.buffer;

    let result_data = bitcast[&[f32]](result_buffer.data);

    let result_buffer_offset = Buffer {
        data = bitcast[&mut[i8]](&result_data(3 * 2)),
        size = 0,
        device = 0
    };

    write_idx_scaled("result.idx", 3, [2, 3, 2], [result_buffer, result_buffer_offset]);
}

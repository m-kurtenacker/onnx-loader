/* Tensor base definition and some utils. */

struct Tensor[T] {
    buffer : Buffer,
    num_dims : i32,
    size_fn: fn(i32) -> i64,
    access_fn: fn(&[i64]) -> &mut T
}

/* Allocate and Release tensors, with different memory layouts as needed */

enum AllocLayout {
    RowMayor,
    ColumnMayor
}

fn @build_tensor_layout[T] (buffer : Buffer, num_dims : i32, size_fn : fn(i32) -> i64, layout : AllocLayout) -> Tensor[T] {
    let access_fn_col = |n : &[i64]| {
        let mut address = n(num_dims - 1);
        for i in unroll(0, num_dims - 1) {
            address = address * size_fn(num_dims - 2 - i) + n(num_dims - 2 - i);
        }
        &mut bitcast[&mut[T]](buffer.data)(address)
    };

    let access_fn_row = |n : &[i64]| {
        let mut address = n(0);
        for i in unroll(1, num_dims) {
            address = address * size_fn(i) + n(i);
        }
        &mut bitcast[&mut[T]](buffer.data)(address)
    };

    Tensor[T] {
        buffer = buffer,
        num_dims = num_dims,
        size_fn = size_fn,
        access_fn = match layout {
            AllocLayout::ColumnMayor => access_fn_col,
            AllocLayout::RowMayor => access_fn_row,
        }
    }
}

fn @alloc_tensor_layout[T] (num_dims : i32, size_fn : fn(i32) -> i64, layout : AllocLayout) -> Tensor[T] {
    let mut size = 1 as i64;
    for i in unroll (0, num_dims) {
        size *= size_fn(i);
    }

    let buffer = get_buffer_managed(sizeof[T]() * size);

    build_tensor_layout[T](buffer, num_dims, size_fn, layout)
}

fn release_tensor[T] (mat : Tensor[T]) -> () { release_buffer_managed(mat.buffer); }

fn @alloc_tensor[T] (num_dims : i32, size_fn : fn(i32) -> i64) = @alloc_tensor_layout[T](num_dims, size_fn, AllocLayout::RowMayor);

#[intern] fn @build_tensor_f32 (buffer: Buffer, num_dims: i32, size_fn : fn(i32) -> i64) = @build_tensor_layout[f32](buffer, num_dims, size_fn, AllocLayout::RowMayor);

#[intern] fn @alloc_tensor_f32 (num_dims: i32, size_fn : fn(i32) -> i64) = @alloc_tensor[f32](num_dims, size_fn);

#[intern] fn @alloc_initializer_f32 (num_dims: i32, size_fn : fn(i32) -> i64) = @alloc_tensor_layout[f32](num_dims, size_fn, AllocLayout::RowMayor);
#[intern] fn @alloc_initializer_i64 (num_dims: i32, size_fn : fn(i32) -> i64) = @alloc_tensor_layout[i64](num_dims, size_fn, AllocLayout::RowMayor);


/* For debuggung output */

static print_enable = true;

fn print_tensor (name: &[u8], mat: Tensor[f32]) -> () {
    if (print_enable) {
        print_string("Tensor ");
        print_string(name);
        print_string(" [");
        for i in range(0, mat.num_dims - 1) {
            print_i64(mat.size_fn(i));
            print_string(" x ");
        }
        print_i64(mat.size_fn(mat.num_dims - 1));
        print_string("]:\n");

        if mat.num_dims == 1 {
            for x in range(0, mat.size_fn(0) as i32) {
                print_f32(*mat.access_fn([x as i64]));
                print_string(" ");
            }
            print_string("\n");
        } else if mat.num_dims == 2 {
            for y in range(0, mat.size_fn(1) as i32) {
                for x in range(0, mat.size_fn(0) as i32) {
                    print_f32(*mat.access_fn([x as i64, y as i64]));
                    print_string(" ");
                }
                print_string("\n");
            }
        } else if mat.num_dims == 3 {
            for chan in range(0, mat.size_fn(2) as i32) {
                print_string("chan_");
                print_i32(chan);
                print_string(":\n");

                for y in range(0, mat.size_fn(0) as i32) {
                    for x in range(0, mat.size_fn(1) as i32) {
                        print_f32(*mat.access_fn([x as i64, y as i64, chan as i64]));
                        print_string(" ");
                    }
                    print_string("\n");
                }
            }
        } else if mat.num_dims == 4 {
            for chan_out in range(0, mat.size_fn(0) as i32) {
                for chan_in in range(0, mat.size_fn(1) as i32) {
                    print_string("chan_");
                    print_i32(chan_out);
                    print_string("x");
                    print_i32(chan_in);
                    print_string(":\n");

                    for x in range(0, mat.size_fn(2) as i32) {
                        for y in range(0, mat.size_fn(3) as i32) {
                            print_f32(*mat.access_fn([chan_out as i64, chan_in as i64, x as i64, y as i64]));
                            print_string(" ");
                        }
                        print_string("\n");
                    }
                }
            }
        } else {
            print_string("Printing error: too many dimensions\n");
        }
    }
}

fn print_tensor_i64 (name: &[u8], mat: Tensor[i64]) -> () {
    if (print_enable) {
        print_string("Tensor ");
        print_string(name);
        print_string(" [");
        for i in range(0, mat.num_dims - 1) {
            print_i64(mat.size_fn(i));
            print_string(" x ");
        }
        print_i64(mat.size_fn(mat.num_dims - 1));
        print_string("]:\n");

        if mat.num_dims == 1 {
            for x in range(0, mat.size_fn(0) as i32) {
                print_i64(*mat.access_fn([x as i64]));
                print_string(" ");
            }
            print_string("\n");
        } else if mat.num_dims == 2 {
            for x in range(0, mat.size_fn(0) as i32) {
                for y in range(0, mat.size_fn(1) as i32) {
                    print_i64(*mat.access_fn([x as i64, y as i64]));
                    print_string(" ");
                }
                print_string("\n");
            }
        } else if mat.num_dims == 3 {
            for chan in range(0, mat.size_fn(2) as i32) {
                print_string("chan_");
                print_i32(chan);
                print_string(":\n");

                for x in range(0, mat.size_fn(1) as i32) {
                    for y in range(0, mat.size_fn(0) as i32) {
                        print_i64(*mat.access_fn([x as i64, y as i64, chan as i64]));
                        print_string(" ");
                    }
                    print_string("\n");
                }
            }
        } else if mat.num_dims == 4 {
            for chan_out in range(0, mat.size_fn(0) as i32) {
                for chan_in in range(0, mat.size_fn(1) as i32) {
                    print_string("chan_");
                    print_i32(chan_out);
                    print_string("x");
                    print_i32(chan_in);
                    print_string(":\n");

                    for x in range(0, mat.size_fn(2) as i32) {
                        for y in range(0, mat.size_fn(3) as i32) {
                            print_i64(*mat.access_fn([chan_out as i64, chan_in as i64, x as i64, y as i64]));
                            print_string(" ");
                        }
                        print_string("\n");
                    }
                }
            }
        } else {
            print_string("Printing error: too many dimensions\n");
        }
    }
}

fn print_tensor_256 (name: &[u8], mat: Tensor[f32]) -> () {
    if (print_enable) {
        print_string("Tensor ");
        print_string(name);
        print_string(" [");
        for i in range(0, mat.num_dims - 1) {
            print_i64(mat.size_fn(i));
            print_string(" x ");
        }
        print_i64(mat.size_fn(mat.num_dims - 1));
        print_string("]:\n");

        if mat.num_dims == 1 {
            for x in range(0, mat.size_fn(0) as i32) {
                print_f32(255 * *mat.access_fn([x as i64]));
                print_string(" ");
            }
            print_string("\n");
        } else if mat.num_dims == 2 {
            for x in range(0, mat.size_fn(0) as i32) {
                for y in range(0, mat.size_fn(1) as i32) {
                    print_f32(255 * *mat.access_fn([x as i64, y as i64]));
                    print_string(" ");
                }
                print_string("\n");
            }
        } else if mat.num_dims == 3 {
            for chan in range(0, mat.size_fn(0) as i32) {
                print_string("chan_");
                print_i32(chan);
                print_string(":\n");

                for x in range(0, mat.size_fn(1) as i32) {
                    for y in range(0, mat.size_fn(2) as i32) {
                        print_f32(255 * *mat.access_fn([chan as i64, x as i64, y as i64]));
                        print_string(" ");
                    }
                    print_string("\n");
                }
            }
        } else if mat.num_dims == 4 {
            for chan_out in range(0, mat.size_fn(0) as i32) { //also batch
                for chan_in in range(0, mat.size_fn(1) as i32) {
                    print_string("chan_");
                    print_i32(chan_out);
                    print_string("x");
                    print_i32(chan_in);
                    print_string(":\n");

                    for x in range(0, mat.size_fn(2) as i32) {
                        for y in range(0, mat.size_fn(3) as i32) {
                            //print_f32(255 * *mat.access_fn([chan_in as i64, chan_out as i64, x as i64, y as i64]));
                            print_f32(255 * *mat.access_fn([chan_out as i64, chan_in as i64, x as i64, y as i64]));
                            print_string(" ");
                        }
                        print_string("\n");
                    }
                }
            }
        } else {
            print_string("Printing error: too many dimensions\n");
        }
    }
}

fn print_array_i64 (name: &[u8], array: &[i64], num_elements: i32) -> () {
    if (print_enable) {
        print_string("Array ");
        print_string(name);
        print_string(" [");
        print_i32(num_elements);
        print_string("]: ");
        for i in range(0, num_elements) {
            if i > 0 {
                print_string(", ");
            }
            print_i64(array(i));
        }
        print_string("\n");
    }
}

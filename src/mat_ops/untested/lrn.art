#[export] static mut time_lrn : i64;

fn @matrix_lrn (manager: PassManager, mat: Tensor[f32], output_size: &[i64]) -> Tensor[f32] {
    let start = get_micro_time();

    fn @output_size_fn(n : i32) -> i64 { output_size(n) }
    let output = @alloc_tensor[f32](3, output_size_fn);

    let num_chan = mat.size_fn(2) as i32;

    for instance in multi_loop (manager, 3, output_size) {
        let chan  = instance.index(2) as i32;

        let start = if 0 > chan - 2 { 0 } else { chan - 2 };
        let stop = if num_chan - 1 < chan + 2 { num_chan - 1 } else { chan + 2 };

        let mut index_copy : [i64 * 3];

        index_copy(0) = instance.index(0);
        index_copy(1) = instance.index(1);

        let mut sqr_sum = 0 : f32;

        for i in range(start, stop + 1) {
            index_copy(2) = i as i64;

            let elem = *mat.access_fn(index_copy);

            sqr_sum += elem * elem;
        }

        let alpha = 0.0001 : f32;
        let beta = 0.75 : f32;
        let bias = 1 : f32; // == k in pytorch

        let index_fixed = [instance.index(0), instance.index(1), instance.index(2)];
        let d = *mat.access_fn(index_fixed);
        let r = d / math_builtins::pow(bias + alpha / 5 * sqr_sum, beta);
        *output.access_fn(index_fixed) = r;
    }

    time_lrn += get_micro_time() - start;

    output
}

#[intern]
fn @matrix_lrn_f32 (manager: PassManager, mat: Tensor[f32], output_size: &[i64]) = @matrix_lrn(manager, mat, output_size);
